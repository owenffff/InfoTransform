{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Logs Explorer\n",
    "\n",
    "Quick analysis of InfoTransform processing logs from SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database: /data/processing_logs.db\n",
      "✅ Exists: False\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Database path\n",
    "DB_PATH = Path('/data/processing_logs.db')\n",
    "\n",
    "def query_db(sql, params=None):\n",
    "    \"\"\"Execute query and return DataFrame\"\"\"\n",
    "    conn = sqlite3.connect(str(DB_PATH))\n",
    "    df = pd.read_sql_query(sql, conn, params=params)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "print(f\"✅ Database: {DB_PATH.absolute()}\")\n",
    "print(f\"✅ Exists: {DB_PATH.exists()}\")\n",
    "if DB_PATH.exists():\n",
    "    print(f\"✅ Size: {DB_PATH.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Summary stats\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m summary = \u001b[43mquery_db\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[33;43m    SELECT \u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m        COUNT(*) as total_runs,\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43m        SUM(total_files) as total_files,\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m        SUM(successful_files) as successful,\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m        SUM(failed_files) as failed,\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[33;43m        SUM(total_tokens) as total_tokens,\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[33;43m        AVG(duration_seconds) as avg_duration\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[33;43m    FROM processing_runs\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[33;43m    WHERE status = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcompleted\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m summary\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mquery_db\u001b[39m\u001b[34m(sql, params)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery_db\u001b[39m(sql, params=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute query and return DataFrame\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     conn = \u001b[43msqlite3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDB_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     df = pd.read_sql_query(sql, conn, params=params)\n\u001b[32m     12\u001b[39m     conn.close()\n",
      "\u001b[31mOperationalError\u001b[39m: unable to open database file"
     ]
    }
   ],
   "source": [
    "# Summary stats\n",
    "summary = query_db(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_runs,\n",
    "        SUM(total_files) as total_files,\n",
    "        SUM(successful_files) as successful,\n",
    "        SUM(failed_files) as failed,\n",
    "        SUM(total_tokens) as total_tokens,\n",
    "        AVG(duration_seconds) as avg_duration\n",
    "    FROM processing_runs\n",
    "    WHERE status = 'completed'\n",
    "\"\"\")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 10 runs\n",
    "recent = query_db(\"\"\"\n",
    "    SELECT \n",
    "        run_id,\n",
    "        start_timestamp,\n",
    "        model_key,\n",
    "        total_files,\n",
    "        successful_files,\n",
    "        total_tokens,\n",
    "        duration_seconds,\n",
    "        status\n",
    "    FROM processing_runs\n",
    "    ORDER BY start_timestamp DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "recent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Usage by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token usage per model\n",
    "tokens_by_model = query_db(\"\"\"\n",
    "    SELECT \n",
    "        model_key,\n",
    "        COUNT(*) as runs,\n",
    "        SUM(total_tokens) as total_tokens,\n",
    "        AVG(total_tokens) as avg_tokens,\n",
    "        SUM(input_tokens) as input_tokens,\n",
    "        SUM(output_tokens) as output_tokens\n",
    "    FROM processing_runs\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY model_key\n",
    "    ORDER BY total_tokens DESC\n",
    "\"\"\")\n",
    "\n",
    "tokens_by_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by model\n",
    "performance = query_db(\"\"\"\n",
    "    SELECT \n",
    "        model_key,\n",
    "        COUNT(*) as runs,\n",
    "        AVG(duration_seconds) as avg_duration,\n",
    "        AVG(total_files) as avg_files,\n",
    "        ROUND(AVG(CAST(successful_files AS FLOAT) / NULLIF(total_files, 0) * 100), 2) as success_rate\n",
    "    FROM processing_runs\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY model_key\n",
    "\"\"\")\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 7 days\n",
    "daily = query_db(\"\"\"\n",
    "    SELECT \n",
    "        DATE(start_timestamp) as date,\n",
    "        COUNT(*) as runs,\n",
    "        SUM(total_files) as files,\n",
    "        SUM(total_tokens) as tokens\n",
    "    FROM processing_runs\n",
    "    WHERE status = 'completed'\n",
    "      AND start_timestamp >= datetime('now', '-7 days')\n",
    "    GROUP BY DATE(start_timestamp)\n",
    "    ORDER BY date DESC\n",
    "\"\"\")\n",
    "\n",
    "daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost estimate (update pricing as needed)\n",
    "INPUT_PRICE_PER_1M = 0.15   # $0.15 per 1M input tokens\n",
    "OUTPUT_PRICE_PER_1M = 0.60  # $0.60 per 1M output tokens\n",
    "\n",
    "cost_df = tokens_by_model.copy()\n",
    "cost_df['input_cost'] = (cost_df['input_tokens'] / 1_000_000) * INPUT_PRICE_PER_1M\n",
    "cost_df['output_cost'] = (cost_df['output_tokens'] / 1_000_000) * OUTPUT_PRICE_PER_1M\n",
    "cost_df['total_cost'] = cost_df['input_cost'] + cost_df['output_cost']\n",
    "\n",
    "print(f\"Total Estimated Cost: ${cost_df['total_cost'].sum():.4f}\")\n",
    "cost_df[['model_key', 'runs', 'total_tokens', 'total_cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all completed runs to CSV\n",
    "all_runs = query_db(\"SELECT * FROM processing_runs WHERE status = 'completed' ORDER BY start_timestamp DESC\")\n",
    "all_runs.to_csv('processing_logs_export.csv', index=False)\n",
    "print(f\"✅ Exported {len(all_runs)} runs to processing_logs_export.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InfoTransform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
